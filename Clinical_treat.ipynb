{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "#from IPython.display import display\n",
    "\n",
    "# Made by Henric Pietro Vicente Gil please credit me in your work :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter here only\n",
    "\n",
    "# Cria a variável que contem a lista de arqquivos que voce quer olhar, se for só um deixa como string\n",
    "path_to_files = \"D:\\\\Projetos academicos\\\\Labmol\\\\Code\\Data\\\\tox21\\\\Datasets\"\n",
    "# To get from a directory\n",
    "file_list=os.listdir(path_to_files)\n",
    "s_file = [f\"{path_to_files}\\\\{file}\" for file in file_list]\n",
    "# To get from a path\n",
    "\n",
    "# s_file=\"D:/Projetos academicos/Labmol/Code/Data/My_data/Clinical Data/Pasta1.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_identifier_column = \"Chemical Structure\"\n",
    "values_col = \"Dose\"\n",
    "max_z_score = 1.8\n",
    "convert_to_p = False # p= -log(measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For cases that contain null chars\n",
    "for file in s_file:        \n",
    "        with open(file,\"r\",) as f:\n",
    "                a=f.read()\n",
    "\n",
    "        a=a.replace(\"\\x00\",\"\")\n",
    "        \n",
    "        with open(file,\"w\") as f:\n",
    "                f.write(a)\n",
    "        # df=pd.read_csv(file,delimiter=\",\")\n",
    "        # print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to excel for compatibility issues\n",
    "for file in s_file:\n",
    "    name=str(file).replace(path_to_files,\"\")\n",
    "    name=name.replace(\".csv\",\".xlsx\")\n",
    "    \n",
    "    df=pd.read_csv(file,delimiter=\",\")\n",
    "    df.to_excel(f\"temp_dataset/{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = \"./temp_dataset\"\n",
    "file_list=os.listdir(path_to_files)\n",
    "s_file = [f\"{path_to_files}\\\\{file}\" for file in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(files):\n",
    "    def isInt(i):\n",
    "        \"\"\"Check if it is an integer\"\"\"\n",
    "        try:\n",
    "            int(i)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def isFloat(f):\n",
    "        try:\n",
    "            float(f)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def convertTo_mg(df, column=values_col):\n",
    "        \"\"\"Pass a series like (aka: df.column) of measurement strings, convert the values into miligram numbers, returns a list o lists with a number and the unit\"\"\"\n",
    "\n",
    "        micro = \"\\u00B5\"\n",
    "        measure = []\n",
    "\n",
    "        for dose in df.loc[:, column]:\n",
    "            # num=[n for n in number if isInt(n) or n==\".\"]\n",
    "            num = \"\"\n",
    "            unit = \"\"\n",
    "            nums = []\n",
    "            avg = 0\n",
    "            # Ensures it is not nan or None\n",
    "            if type(dose) is str:\n",
    "                for i, n in enumerate(dose):\n",
    "                    # Avoids unprecise entries\n",
    "                    if n in [\"<\", \">\"]:\n",
    "                        continue\n",
    "\n",
    "                    if isInt(n) or n == \".\" and num.find(\".\") == -1:\n",
    "                        num += n\n",
    "\n",
    "                    if isInt(n) == False:\n",
    "                        unit += n\n",
    "                        num = \"\"\n",
    "                    if n in [\",\", \"-\", \"\\\\\", \".\", \"/\"] and num.find(\".\") != 0 and num != \"\":\n",
    "                        num.strip(\" ,-\\\\/\")\n",
    "                        nums.append(float(num))\n",
    "                        num = \"\"\n",
    "                    if len(nums) > 1 and \"\" not in nums:\n",
    "                        avg = np.mean(nums)\n",
    "\n",
    "                    elif len(nums) == 0 and num != \"\":\n",
    "                        avg = float(num)\n",
    "                # unit=[str(s) for s in number if isInt(s)==False]\n",
    "                measure.append([avg, str(unit).strip(\" -.\")])\n",
    "\n",
    "            elif type(dose) is float or type(dose) is int:\n",
    "                measure.append([dose, \"mg\"])\n",
    "        for i, m in enumerate(measure):\n",
    "            # print(m)\n",
    "            u = str(m[1])\n",
    "            n = m[0]\n",
    "\n",
    "            # if you want to use the strings that contain unit values uncomment the commented lines\n",
    "            if u.find(\"kg\") != -1 and u.find(\"mg\") == -1:\n",
    "                measure[i][0] = n*1_000_000\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"kg\",\"mg\")\n",
    "\n",
    "            # might be with special char\n",
    "            elif u.find(f\"{micro}g\") != -1 or unit.find(\"ug\") != -1:\n",
    "                measure[i][0] = n/1000\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"ug\",\"mg\")\n",
    "\n",
    "            elif u.find(\"cg\") != -1:\n",
    "                measure[i][0] = n*10\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"cg\",\"mg\")\n",
    "            if u.find(\"mg\") == 0:\n",
    "                measure[i][0] = n\n",
    "\n",
    "            if u.find(\"g\") == 0:\n",
    "                measure[i][0] = n*1000\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"g\",\"mg\")\n",
    "\n",
    "        solved_col = pd.Series(measure)\n",
    "\n",
    "        return solved_col\n",
    "    # Method that calculates the standard deviation with a number list and the mean, but use np.std() instead\n",
    "\n",
    "\n",
    "    def stdCalculation(numList, mean):\n",
    "        n = len(numList)+1\n",
    "        soma = 0\n",
    "        for x in numList:\n",
    "            soma += (x-mean)**2\n",
    "        std = math.sqrt((soma)/n)\n",
    "        return std\n",
    "    # Method to calculate the z score for each number in a array of numbers, returns a list of z-scores of each number relevant to the array\n",
    "\n",
    "\n",
    "    def z_scorer(nums: list, mean: float or int, std: float or int):\n",
    "\n",
    "        z_scores = []\n",
    "        for x in nums:\n",
    "            z = (x-mean)/std\n",
    "            z_scores.append(z)\n",
    "        return z_scores\n",
    "\n",
    "    # Most of the action happens here\n",
    "\n",
    "\n",
    "    def idOutliers(df: pd.DataFrame, name_col: str = \"Drug\", value_col: str = \"Dose\", max_z: float = 1.8,convert_to_p: bool=True):\n",
    "        dict_rows = {}\n",
    "        means = {}\n",
    "        # Comment if you have empty values\n",
    "        df = df.dropna(axis=0, how=\"all\")\n",
    "\n",
    "        values = [num for num, mg in df.loc[:, value_col]]\n",
    "\n",
    "        names = [drugs for drugs in df.loc[:, name_col] if type(drugs) is str]\n",
    "        for i, name in enumerate(names):\n",
    "\n",
    "            if name not in dict_rows:\n",
    "                dict_rows[name] = []\n",
    "\n",
    "                dict_rows[name].append(values[i])\n",
    "            else:\n",
    "                dict_rows[name].append(values[i])\n",
    "\n",
    "        for n in dict_rows:\n",
    "            media = []\n",
    "            if len(dict_rows[n]) > 1 and type(dict_rows[n]) is float:\n",
    "                means[n] = np.mean(dict_rows[n])\n",
    "\n",
    "                if dict_rows[n][0]!=0 and means[n]/dict_rows[n][0] != 1:\n",
    "                    std = np.std(dict_rows[n])\n",
    "                else:\n",
    "                    std = 1\n",
    "\n",
    "                z = z_scorer(dict_rows[n], means[n], std)\n",
    "\n",
    "                for _i, i in enumerate(z):\n",
    "                    if abs(i) <= max_z:\n",
    "                        media.append(dict_rows[n][_i])\n",
    "\n",
    "                med = np.mean(media)\n",
    "                # atrubutes where in the column specified is equal to the name of the current row, and replaces the value (dose) of that row\n",
    "                if convert_to_p:\n",
    "                    df.loc[df[name_col] == n, value_col] = -math.log10(med)\n",
    "                else:\n",
    "                    df.loc[df[name_col] == n, value_col] = med\n",
    "            else:\n",
    "                if convert_to_p:\n",
    "                    if dict_rows[n][0] <= 0:\n",
    "                        df.loc[df[name_col] == n, value_col] = dict_rows[n][0]\n",
    "                    else: \n",
    "                        df.loc[df[name_col] == n, value_col] = -math.log10(dict_rows[n][0])\n",
    "                else:\n",
    "                    df.loc[df[name_col] == n, value_col] = dict_rows[n][0]\n",
    "\n",
    "        return df\n",
    "    # computes in the order necessary to generate the dataframes\n",
    "\n",
    "\n",
    "    def organize(file,sheet):\n",
    "        # read\n",
    "        print(file)\n",
    "        name=str(file).replace(path_to_files,\"\")\n",
    "        name=name.replace(\".xlsx\",\"\")\n",
    "        # if file.find(\".csv\")!=-1:\n",
    "        #     df = pd.read_csv(file,delimiter=\",\")\n",
    "        #     name=str(file).replace(path_to_files,\"\")\n",
    "\n",
    "        # elif file.find(\".xlsx\")!=-1 and sheet is not None:\n",
    "        #     name=sheet\n",
    "        df = pd.read_excel(file, sheet_name=sheet) \n",
    "            \n",
    "\n",
    "        # convert\n",
    "        new_doses = convertTo_mg(df, values_col)\n",
    "        # assign to the df\n",
    "        df[values_col] = new_doses\n",
    "        # generate\n",
    "        z = idOutliers(df, duplicate_identifier_column, values_col,max_z_score,convert_to_p)\n",
    "        z = z.drop_duplicates(keep=\"first\",subset=duplicate_identifier_column)\n",
    "        \n",
    "        \n",
    "        z.to_excel(f\"./results/{name}.xlsx\")\n",
    "        print(f\"Generated: {name}.xlsx\")\n",
    "        # confirm\n",
    "        if sheet==\"Planilha1\":\n",
    "            print(f\"generated {name}.xlsx dataframe\")\n",
    "\n",
    "    # Made to work with a single file and a list of files\n",
    "\n",
    "\n",
    "    def read_through_files(files):\n",
    "\n",
    "        if type(files) is str:\n",
    "            if files.find(\".csv\")!=-1:\n",
    "                organize(files)\n",
    "            else:\n",
    "                sheets = pd.ExcelFile(files).sheet_names\n",
    "                for sheet in sheets:\n",
    "                    if sheet != \".\":\n",
    "                        organize(files,sheet=sheet)\n",
    "        else:\n",
    "            for file in files:\n",
    "                if file.find(\".csv\")!=-1:\n",
    "                    organize(file)\n",
    "                else:   \n",
    "                    sheets = pd.ExcelFile(file).sheet_names\n",
    "                    for sheet in sheets:\n",
    "                        organize(file,sheet)\n",
    "    \n",
    "    read_through_files(files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./temp_dataset\\tox21-ahr-p1.xlsx\n",
      "Generated: \\tox21-ahr-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-ap1-agonist-p1.xlsx\n",
      "Generated: \\tox21-ap1-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-ar-bla-agonist-p1.xlsx\n",
      "Generated: \\tox21-ar-bla-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-ar-bla-antagonist-p1.xlsx\n",
      "Generated: \\tox21-ar-bla-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-ar-mda-kb2-luc-agonist-p1.xlsx\n",
      "Generated: \\tox21-ar-mda-kb2-luc-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-ar-mda-kb2-luc-agonist-p3.xlsx\n",
      "Generated: \\tox21-ar-mda-kb2-luc-agonist-p3_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-ar-mda-kb2-luc-antagonist-p1.xlsx\n",
      "Generated: \\tox21-ar-mda-kb2-luc-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-ar-mda-kb2-luc-antagonist-p2.xlsx\n",
      "Generated: \\tox21-ar-mda-kb2-luc-antagonist-p2_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-are-bla-p1.xlsx\n",
      "Generated: \\tox21-are-bla-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-aromatase-p1.xlsx\n",
      "Generated: \\tox21-aromatase-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-car-agonist-p1.xlsx\n",
      "Generated: \\tox21-car-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-car-antagonist-p1.xlsx\n",
      "Generated: \\tox21-car-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-casp3-cho-p1.xlsx\n",
      "Generated: \\tox21-casp3-cho-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-casp3-hepg2-p1.xlsx\n",
      "Generated: \\tox21-casp3-hepg2-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-dt40-p1.xlsx\n",
      "Generated: \\tox21-dt40-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-elg1-luc-agonist-p1.xlsx\n",
      "Generated: \\tox21-elg1-luc-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-er-bla-agonist-p2.xlsx\n",
      "Generated: \\tox21-er-bla-agonist-p2_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-er-bla-antagonist-p1.xlsx\n",
      "Generated: \\tox21-er-bla-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-er-luc-bg1-4e2-agonist-p2.xlsx\n",
      "Generated: \\tox21-er-luc-bg1-4e2-agonist-p2_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-er-luc-bg1-4e2-agonist-p4.xlsx\n",
      "Generated: \\tox21-er-luc-bg1-4e2-agonist-p4_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-er-luc-bg1-4e2-antagonist-p1.xlsx\n",
      "Generated: \\tox21-er-luc-bg1-4e2-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-er-luc-bg1-4e2-antagonist-p2.xlsx\n",
      "Generated: \\tox21-er-luc-bg1-4e2-antagonist-p2_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-erb-bla-antagonist-p1.xlsx\n",
      "Generated: \\tox21-erb-bla-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-erb-bla-p1.xlsx\n",
      "Generated: \\tox21-erb-bla-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-err-p1.xlsx\n",
      "Generated: \\tox21-err-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-esre-bla-p1.xlsx\n",
      "Generated: \\tox21-esre-bla-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-fxr-bla-agonist-p2.xlsx\n",
      "Generated: \\tox21-fxr-bla-agonist-p2_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-gh3-tre-agonist-p1.xlsx\n",
      "Generated: \\tox21-gh3-tre-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-gh3-tre-antagonist-p1.xlsx\n",
      "Generated: \\tox21-gh3-tre-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-gr-hela-bla-agonist-p1.xlsx\n",
      "Generated: \\tox21-gr-hela-bla-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-gr-hela-bla-antagonist-p1.xlsx\n",
      "Generated: \\tox21-gr-hela-bla-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-h2ax-cho-p2.xlsx\n",
      "Generated: \\tox21-h2ax-cho-p2_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-hdac-p1.xlsx\n",
      "Generated: \\tox21-hdac-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-hre-bla-agonist-p1.xlsx\n",
      "Generated: \\tox21-hre-bla-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-hse-bla-p1.xlsx\n",
      "Generated: \\tox21-hse-bla-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-luc-biochem-p1.xlsx\n",
      "Generated: \\tox21-luc-biochem-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-mitotox-p1.xlsx\n",
      "Generated: \\tox21-mitotox-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-nfkb-bla-agonist-p1.xlsx\n",
      "Generated: \\tox21-nfkb-bla-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-p53-bla-p1.xlsx\n",
      "Generated: \\tox21-p53-bla-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-pgc-err-p1.xlsx\n",
      "Generated: \\tox21-pgc-err-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-ppard-bla-agonist-p1.xlsx\n",
      "Generated: \\tox21-ppard-bla-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-ppard-bla-antagonist-p1.xlsx\n",
      "Generated: \\tox21-ppard-bla-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-pparg-bla-agonist-p1.xlsx\n",
      "Generated: \\tox21-pparg-bla-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-pparg-bla-antagonist-p1.xlsx\n",
      "Generated: \\tox21-pparg-bla-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-pr-bla-agonist-p1.xlsx\n",
      "Generated: \\tox21-pr-bla-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-pr-bla-antagonist-p1.xlsx\n",
      "Generated: \\tox21-pr-bla-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-pxr-p1.xlsx\n",
      "Generated: \\tox21-pxr-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-rar-agonist-p1.xlsx\n",
      "Generated: \\tox21-rar-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-rar-antagonist-p2.xlsx\n",
      "Generated: \\tox21-rar-antagonist-p2_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-rar-viability-p2.xlsx\n",
      "Generated: \\tox21-rar-viability-p2_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-ror-cho-antagonist-p1.xlsx\n",
      "Generated: \\tox21-ror-cho-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-ror-cho-viability-p1.xlsx\n",
      "Generated: \\tox21-ror-cho-viability-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-rt-viability-hek293-p1.xlsx\n",
      "Generated: \\tox21-rt-viability-hek293-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-rt-viability-hepg2-p1.xlsx\n",
      "Generated: \\tox21-rt-viability-hepg2-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-rxr-bla-agonist-p1.xlsx\n",
      "Generated: \\tox21-rxr-bla-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-sbe-bla-agonist-p1.xlsx\n",
      "Generated: \\tox21-sbe-bla-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-sbe-bla-antagonist-p1.xlsx\n",
      "Generated: \\tox21-sbe-bla-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-shh-3t3-gli3-agonist-p1.xlsx\n",
      "Generated: \\tox21-shh-3t3-gli3-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-shh-3t3-gli3-antagonist-p1.xlsx\n",
      "Generated: \\tox21-shh-3t3-gli3-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-spec-hek293-p1.xlsx\n",
      "Generated: \\tox21-spec-hek293-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-spec-hepg2-p1.xlsx\n",
      "Generated: \\tox21-spec-hepg2-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-trhr-hek293-p1.xlsx\n",
      "Generated: \\tox21-trhr-hek293-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-tshr-agonist-p1.xlsx\n",
      "Generated: \\tox21-tshr-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-tshr-antagonist-p1.xlsx\n",
      "Generated: \\tox21-tshr-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-tshr-wt-p1.xlsx\n",
      "Generated: \\tox21-tshr-wt-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-vdr-bla-agonist-p1.xlsx\n",
      "Generated: \\tox21-vdr-bla-agonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\tox21-vdr-bla-antagonist-p1.xlsx\n",
      "Generated: \\tox21-vdr-bla-antagonist-p1_Sheet1.xlsx\n",
      "./temp_dataset\\ttox21-fxr-bla-antagonist-p1.xlsx\n",
      "Generated: \\ttox21-fxr-bla-antagonist-p1_Sheet1.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Execute everything\n",
    "main(s_file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
