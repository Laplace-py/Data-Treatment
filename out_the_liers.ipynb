{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "#from IPython.display import display\n",
    "\n",
    "# Made by Henric Pietro Vicente Gil please credit me in your work :) \n",
    "# henricgil@discente.ufg.br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# This cell defines the location of the files, \n",
    "\n",
    "# path_to_files may be a folder where multiple files are;\n",
    "\n",
    "# file_list is a list of all the files in the folder provided in path_to_files;\n",
    "\n",
    "# s_file represents the file(s) to be read, can be either a list or a string\n",
    "\n",
    "# uncomment the part that you will use, comment the part you wont\n",
    "\"\"\"\n",
    "\n",
    "# Points to a file ./myfolder/example.xlsx or to a folder c:\\\\my\\\\folder\\\\where\\\\my\\\\\\files\\\\are\n",
    "path_to_files = \"D:\\\\Projetos academicos\\\\Labmol\\\\Code\\\\Data\\\\My_data\\\\Clinical Data\\\\Legacy_Data\\\\Filtered_Clinical_Data.xlsx\"\n",
    "# if its a single file pass its name\n",
    "result_name=\"Results\"\n",
    "try:\n",
    "    os.mkdir(\"./data\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "#### To get from a directory\n",
    "\n",
    "#file_list=os.listdir(path_to_files)\n",
    "#s_file = [f\"{path_to_files}\\\\{file}\" for file in file_list]\n",
    "\n",
    "#### To get from a path\n",
    "\n",
    "s_file=path_to_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Defines the necessary variables used all through out the code\n",
    "\n",
    "# duplicate_identifier_column is the collumn that identifies the duplicates in your code\n",
    "\n",
    "# values_col defines the column where your dose/lc50/ic50... values are\n",
    "\n",
    "# max_z_score is the z value used to separate the outliers from non outliers\n",
    "\n",
    "# convert_to_p despite the name, this bool conditions the result into a -log(result) or pResult\n",
    "\n",
    "# convert_measure bool that conditions if you need to convert measurements, also eliminates impossible values\n",
    "\"\"\"\n",
    "duplicate_identifier_column = \"Chemical Structure\"\n",
    "values_col = \"Dose\"\n",
    "max_z_score = 3\n",
    "convert_to_p = True # p = -log(measure)\n",
    "convert_measure = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pandas_convert_excel_to_csv(files : str or list):\n",
    "    if type(files) is list:\n",
    "        for file in files:\n",
    "            if file.find(\".xlsx\")!=-1:\n",
    "                sheets = pd.ExcelFile(file).sheet_names\n",
    "                for sheet in sheets:\n",
    "                    df = pd.read_excel(file,sheet_name=sheet)\n",
    "                    df.to_csv(f\"./temp_dataset/{file}_{sheet}.csv\")\n",
    "    else:\n",
    "        if files.find(\".xlsx\")!=-1:\n",
    "            sheets = pd.ExcelFile(files).sheet_names\n",
    "            for sheet in sheets:\n",
    "                df = pd.read_excel(files,sheet_name=sheet)\n",
    "                df.to_csv(f\"./temp_dataset/{files}_{sheet}.csv\")\n",
    "try:\n",
    "    os.mkdir(\"./temp_dataset\")\n",
    "    pandas_convert_excel_to_csv(s_file)\n",
    "    s_file = [f\"{path_to_files}\\\\{file}\" for file in os.listdir(\"./temp_dataset\")]\n",
    "except FileExistsError:\n",
    "    pandas_convert_excel_to_csv(s_file)\n",
    "    s_file = [f\"{path_to_files}\\\\{file}\" for file in os.listdir(\"./temp_dataset\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize thy molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "from rdkit.Chem.rdmolops import FindPotentialStereo\n",
    "from chembl_structure_pipeline import standardizer \n",
    "from rdkit.Chem.SaltRemover import SaltRemover\n",
    "\n",
    "def standardize(df:pd.DataFrame,name):\n",
    "    name_smiles=\"Chemical Structure\"\n",
    "    METALS=[\"B\",\"Li\",\"Na\",\"K\",\"Rb\",\"Cs\",\"Be\",\"Mg\",\"Ca\",\"Sr\",\"Ba\",\"Ra\",\"Sc\",\"Ti\",\"V\",\"Cr\",\"Mn\",\"Fe\",\"Co\",\"Ni\",\"Cu\",\"Zn\",\"Al\",\"Ga\",\"Y\",\"Zr\",\"Nb\",\"Mo\",\"Tc\",\"Ru\",\"Rh\",\"Pd\",\"Ag\",\"Cd\",\"In\",\"Sn\",\"Hf\",\"Ta\",\"W\",\"Re\",\"Os\",\"Ir\",\"Pt\",\"Au\",\"Hg\",\"Tl\",\"Pb\",\"Bi\"]\n",
    "    NON_METALS=[\"Br\",\"Cl\",\"F\",\"Br-\",\"Cl-\",\"F-\",\"Br--\",\"Cl--\",\"F--\",\"B+\",\"Cl+\",\"F+\",\"Br++\",\"Cl++\",\"F++\",\"O\",\"O-\",\"O--\",\"O+\",\"O++\"]\n",
    "    #df.dropna(subset=name_smiles,how=\"any\",axis=0,inplace=True)\n",
    "    fonte=\"Source\"\n",
    "    removals=[]\n",
    "    \n",
    "    \n",
    "    # for col in df.columns:\n",
    "    #     if col.lower() in fontes:\n",
    "    #        fonte=col\n",
    "    #        break\n",
    "    # file_reference=df.loc[0,fonte]\n",
    "        #removals_df={key:[] for key in [fonte,name_smiles]}\n",
    "\n",
    "    \n",
    "    def remove_non_str(df:pd.DataFrame):\n",
    "            invalids=0\n",
    "            for i,smi in enumerate(df[name_smiles]):\n",
    "                    if type(smi) is not str:\n",
    "                        invalids+=1\n",
    "                        #df.drop(index=i,axis=0 ,inplace=True)\n",
    "                    # try:\n",
    "                    #     smiles = df[name_smiles][i]\n",
    "                    #     m = Chem.MolFromSmiles(smiles)\n",
    "                    #     if m is None:\n",
    "                    #         invalids+=1\n",
    "                    #         df.drop(index=i,axis=0 ,inplace=True)\n",
    "                    # except TypeError:\n",
    "                    #     invalids+=1\n",
    "                    #     df.drop(index=i,axis=0 ,inplace=True)\n",
    "                        nf=df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                        removals.append([f\"Index: {i}\",nf[0],nf[1],\"Empty or not an smiles entry\"])\n",
    "                        df.drop(index=i,axis=0 ,inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            return df,invalids\n",
    "\n",
    "    def remove_invalid(df:pd.DataFrame):\n",
    "        invalids=0\n",
    "        for i,smi in enumerate(df[name_smiles]):\n",
    "            #if type(smi) is not str:    \n",
    "            try:\n",
    "                m = Chem.MolFromSmiles(smi)\n",
    "                if m is None:\n",
    "                    invalids+=1\n",
    "                    nf=df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                    removals.append([nf[0],nf[1],\"invalid\"])\n",
    "                    df.drop(index=i,axis=0 ,inplace=True)\n",
    "            except TypeError:\n",
    "                    invalids+=1\n",
    "                    nf=df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                    removals.append([nf[0],nf[1],\"invalid\"])\n",
    "                    df.drop(index=i,axis=0 ,inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            return df,invalids\n",
    "\n",
    "    def remove_metals(df:pd.DataFrame):\n",
    "        #badAtoms = Chem.MolFromSmarts('[!$([#1,#3,#11,#19,#4,#12,#20,#5,#6,#14,#7,#15,#8,#16,#9,#17,#35,#53])]')\n",
    "        hm_metal=0\n",
    "        hm_mixture=0\n",
    "        for i,smiles in enumerate(df[name_smiles]):\n",
    "            #smiles = df[i]\n",
    "            if type(smiles) is str:\n",
    "                \"\"\"6\"\"\"\n",
    "                if smiles.find(\".\")!=-1:\n",
    "                    is_mixture=str(smiles).split(\".\")\n",
    "                    non_metal_index=[]\n",
    "                    for n,fragment in enumerate(is_mixture):\n",
    "                        for metal in METALS:\n",
    "                            striped=fragment.strip(\"+-[] \")\n",
    "                            #print(len(striped))\n",
    "                            if len(striped)>2 and striped.find(metal)==-1:# and striped not in NON_METALS and striped not in METALS:\n",
    "                                    if n not in non_metal_index:\n",
    "                                        non_metal_index.append(n)\n",
    "                                    else:\n",
    "                                        continue\n",
    "                            else:\n",
    "                                continue\n",
    "                    #print(len(non_metal_index))\n",
    "                    try:\n",
    "                        if len(non_metal_index)>=2: #and (is_mixture[non_metal_index[0]]).strip(\"-+[] \") not in NON_METALS and (is_mixture[non_metal_index[0]]).strip(\"-+[]\") not in METALS:\n",
    "                            nf=df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                            removals.append([f\"Index: {i}\",nf[0],nf[1],\"Mixture\"])\n",
    "                            df.drop(index=i,axis=0,inplace=True)\n",
    "                            hm_mixture+=1\n",
    "                        elif len(non_metal_index)==1:\n",
    "\n",
    "                            df.loc[i,name_smiles] = is_mixture[non_metal_index[0]]\n",
    "                        \n",
    "                        elif len(non_metal_index)==0:\n",
    "                            hm_metal+=1\n",
    "                            nf=df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                            removals.append([f\"Index: {i}\",nf[0],nf[1],\"Salt or metal\"])\n",
    "                            df.drop(index=i,axis=0,inplace=True)\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "                else:\n",
    "                    try:\n",
    "                        for metal in METALS:\n",
    "                            if smiles.find(metal)!=-1 and smiles.find(\"Br\")==-1:\n",
    "                                hm_metal+=1\n",
    "                                nf=df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                                removals.append([f\"Index: {i}\",nf[0],nf[1],\"organometal\"])\n",
    "                                df.drop(index=i,axis=0,inplace=True)\n",
    "                                break\n",
    "                    except KeyError:\n",
    "                        continue    \n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "                            \n",
    "        #df.reset_index(drop=True, inplace=True)                    \n",
    "        return df,hm_metal,hm_mixture\n",
    "\n",
    "    def no_stereoisomer_info(df:pd.DataFrame):\n",
    "        mols = []\n",
    "        for smi in df[name_smiles]:\n",
    "            smi = str(smi).replace(\"@\",\"\")\n",
    "            mols.append(smi)\n",
    "        no_stereoisomer = pd.DataFrame(mols, columns=[\"no_stereoisomer\"])\n",
    "        df_stereoisomer = df.join(no_stereoisomer)\n",
    "        return df_stereoisomer\n",
    "    # Removes stereochemistry info and adds it to \"no_stereo\"\n",
    "    def chemblStandardizer(df:pd.DataFrame):\n",
    "        mols = [Chem.MolFromSmiles(smile) for smile in df[name_smiles] if smile is str]\n",
    "        invalids=0\n",
    "        for i,mol in enumerate(mols):\n",
    "            try:\n",
    "                smiles = Chem.MolToSmiles(standardizer.standardize_mol(mol))\n",
    "                df.loc[i,name_smiles]=smiles    \n",
    "            except:\n",
    "                try:\n",
    "                    nf=df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                    removals.append([f\"Index: {i}\",nf[0],nf[1],\"Even Landrum couldnt do it\"])\n",
    "                    df.drop(index=i,axis=0 ,inplace=True)\n",
    "                    invalids+=1\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        return df,invalids\n",
    "\n",
    "    def standardize_with_and_out_stereo(df) -> pd.DataFrame:\n",
    "        df,invalids = remove_non_str(df)\n",
    "        df,real_invalids = chemblStandardizer(df)\n",
    "        df,hm_metal,hm_mixture = remove_metals(df)\n",
    "        df = no_stereoisomer_info(df)\n",
    "        invalids=invalids+real_invalids\n",
    "        removals_df = pd.DataFrame(removals,columns=[\"Index on that table\",fonte,name_smiles,\"What Happened\"],index=range(len(removals)))\n",
    "        removals_df.to_csv(f\"./data/{name}_Removals.csv\")\n",
    "        return df,hm_metal,hm_mixture,invalids#,norm,neutr,taut\n",
    "\n",
    "    \n",
    "    #generates mol from smiles\n",
    "    \n",
    "    \n",
    "    return standardize_with_and_out_stereo(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO NOT RUN UNLESS YOUR DATA CONTAINS NULL CHARS ########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######### DO NOT RUN UNLESS YOUR DATA CONTAINS NULL CHARS ################\n",
    "\n",
    "for file in s_file:        \n",
    "        with open(file,\"r\") as f:\n",
    "                a=f.read()\n",
    "\n",
    "        a=a.replace(\"\\x00\",\"\")\n",
    "        \n",
    "        with open(file,\"w\") as f:\n",
    "                f.write(a)\n",
    "        # df=pd.read_csv(file,delimiter=\",\")\n",
    "        # print(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DONT RUN UNLESS YOUR FILES HAVE SOME COMPATIBILITY ISSUES #######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DONT RUN UNLESS YOUR FILES HAVE SOME COMPATIBILITY ISSUES #######\n",
    "if type(s_file) is not str:\n",
    "    for file in s_file:\n",
    "        name=str(file).replace(path_to_files,\"\")\n",
    "        name=name.replace(\".csv\",\".xlsx\")\n",
    "        \n",
    "        df=pd.read_csv(file,delimiter=\",\")\n",
    "        df.to_excel(f\"temp_dataset/{name}\")\n",
    "\n",
    "path_to_files = \"./temp_dataset\"\n",
    "file_list=os.listdir(path_to_files)\n",
    "s_file = [f\"{path_to_files}\\\\{file}\" for file in file_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defintively run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(files):\n",
    "    \n",
    "    def isInt(i):\n",
    "        \"\"\"Check if it is an integer\"\"\"\n",
    "        try:\n",
    "            int(i)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def isFloat(f):\n",
    "        try:\n",
    "            float(f)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def convertTo_mg(df, column=values_col):\n",
    "        \"\"\"\n",
    "        Pass a pandas 'series like' (aka: df.column) of measurement strings, \n",
    "        convert the values into miligram numbers, \n",
    "        returns a list of lists with a number and the unit\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        micro = \"\\u00B5\"\n",
    "        measure = []\n",
    "\n",
    "        for dose in df.loc[:, column]:\n",
    "            # num=[n for n in number if isInt(n) or n==\".\"]\n",
    "            num = \"\"\n",
    "            unit = \"\"\n",
    "            nums = []\n",
    "            avg = 0\n",
    "            # Ensures it is not nan or None\n",
    "            if type(dose) is str:\n",
    "                for i, n in enumerate(dose):\n",
    "                    # Avoids unprecise entries\n",
    "                    if n in [\"<\", \">\"]:\n",
    "                        continue\n",
    "\n",
    "                    if isInt(n) or n == \".\" and num.find(\".\") == -1:\n",
    "                        num += n\n",
    "\n",
    "                    if isInt(n) == False:\n",
    "                        unit += n\n",
    "                        num = \"\"\n",
    "                    if n in [\",\", \"-\", \"\\\\\", \".\", \"/\"] and num.find(\".\") != 0 and num != \"\":\n",
    "                        num.strip(\" ,-\\\\/\")\n",
    "                        nums.append(float(num))\n",
    "                        num = \"\"\n",
    "                    if len(nums) > 1 and \"\" not in nums:\n",
    "                        avg = np.mean(nums)\n",
    "\n",
    "                    elif len(nums) == 0 and num != \"\":\n",
    "                        avg = float(num)\n",
    "                # unit=[str(s) for s in number if isInt(s)==False]\n",
    "                measure.append([avg, str(unit).strip(\" -.\")])\n",
    "\n",
    "            elif type(dose) is float or type(dose) is int:\n",
    "                measure.append([dose, \"mg\"])\n",
    "        for i, m in enumerate(measure):\n",
    "            # print(m)\n",
    "            u = str(m[1])\n",
    "            n = m[0]\n",
    "\n",
    "            # if you want to use the strings that contain unit values uncomment the commented lines\n",
    "            if u.find(\"kg\") != -1 and u.find(\"mg\") == -1:\n",
    "                measure[i][0] = n*1_000_000\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"kg\",\"mg\")\n",
    "\n",
    "            # might be with special char\n",
    "            elif u.find(f\"{micro}g\") != -1 or unit.find(\"ug\") != -1:\n",
    "                measure[i][0] = n/1000\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"ug\",\"mg\")\n",
    "\n",
    "            elif u.find(\"cg\") != -1:\n",
    "                measure[i][0] = n*10\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"cg\",\"mg\")\n",
    "            if u.find(\"mg\") == 0:\n",
    "                measure[i][0] = n\n",
    "\n",
    "            if u.find(\"g\") == 0:\n",
    "                measure[i][0] = n*1000\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"g\",\"mg\")\n",
    "\n",
    "        solved_col = pd.Series(measure)\n",
    "\n",
    "        return solved_col\n",
    "    \n",
    "    # Method that calculates the standard deviation with a number list and the mean, but use np.std() instead\n",
    "    def stdCalculation(numList, mean):\n",
    "        n = len(numList)+1\n",
    "        soma = 0\n",
    "        for x in numList:\n",
    "            soma += (x-mean)**2\n",
    "        std = math.sqrt((soma)/n)\n",
    "        return std\n",
    "\n",
    "    # Method to calculate the z score for each number in a array of numbers, returns a list of z-scores of each number relevant to the array\n",
    "    def z_scorer(nums: list, mean: float or int, std: float or int):\n",
    "\n",
    "        z_scores = []\n",
    "        for x in nums:\n",
    "            z = (x-mean)/std\n",
    "            z_scores.append(z)\n",
    "        return z_scores\n",
    "\n",
    "    # Most of the action happens here\n",
    "    def idOutliers(df: pd.DataFrame, name_col: str = \"Drug\", value_col: str = \"Dose\", max_z: float = 1.8, convert_to_p: bool=True):\n",
    "        dict_rows = {}\n",
    "        means = {}\n",
    "        # Comment if you have empty values\n",
    "        df = df.dropna(axis=0, how=\"all\")\n",
    "        \n",
    "        if convert_measure:\n",
    "            values = [num for num, mg in df.loc[:, value_col]]\n",
    "        else:\n",
    "            values = [num for num in df.loc[:, value_col]]\n",
    "        \n",
    "        names = [drugs for drugs in df.loc[:, name_col] if type(drugs) is str]\n",
    "        for i, name in enumerate(names):\n",
    "            if name==\"\" or name==\"-\":\n",
    "                name=\"Empty\"\n",
    "                \n",
    "            if name not in dict_rows:\n",
    "                dict_rows[name] = []\n",
    "                \n",
    "                dict_rows[name].append(values[i])\n",
    "            else:\n",
    "                dict_rows[name].append(values[i])\n",
    "\n",
    "        for n in dict_rows:\n",
    "            media = []\n",
    "            if len(dict_rows[n]) > 1 and type(dict_rows[n]) is float:\n",
    "                means[n] = np.mean(dict_rows[n])\n",
    "\n",
    "                if dict_rows[n][0]!=0 and means[n]/dict_rows[n][0] != 1:\n",
    "                    std = np.std(dict_rows[n])\n",
    "                else:\n",
    "                    std = 1\n",
    "\n",
    "                z = z_scorer(dict_rows[n], means[n], std)\n",
    "\n",
    "                for _i, i in enumerate(z):\n",
    "                    if abs(i) <= max_z:\n",
    "                        media.append(dict_rows[n][_i])\n",
    "\n",
    "                med = np.mean(media)\n",
    "                # atrubutes where in the column specified is equal to the name of the current row, and replaces the value (dose) of that row\n",
    "                if convert_to_p:\n",
    "                    df.loc[df[name_col] == n, value_col] = -math.log10(med)\n",
    "                else:\n",
    "                    df.loc[df[name_col] == n, value_col] = med\n",
    "            else:\n",
    "                if convert_to_p:\n",
    "                    if dict_rows[n][0] <= 0:\n",
    "                        df.loc[df[name_col] == n, value_col] = dict_rows[n][0]\n",
    "                    else: \n",
    "                        df.loc[df[name_col] == n, value_col] = -math.log10(dict_rows[n][0])\n",
    "                else:\n",
    "                    df.loc[df[name_col] == n, value_col] = dict_rows[n][0]\n",
    "            dups = len(values) - len(dict_rows.keys())\n",
    "        return df,dups\n",
    "    \n",
    "    # computes in the order necessary to generate the dataframes\n",
    "    def organize(df,name):\n",
    "        # read\n",
    "        print(name)    \n",
    "        # convert?\n",
    "        if convert_measure:\n",
    "            new_doses = convertTo_mg(df, values_col)\n",
    "            df[values_col] = new_doses\n",
    "        # generate\n",
    "        df,hm_metal,hm_mixture,invalids= standardize(df,name)\n",
    "        z,dups = idOutliers(df, duplicate_identifier_column, values_col, max_z_score, convert_to_p)\n",
    "        text=f\"With stereo entries {name}: \\n Removed metals: {hm_metal} \\t Removed mixtures: {hm_mixture} \\t Invalids removed: {invalids} \\t Removed duplicates: {dups} \\t \\n \\n\"\n",
    "        z = z.drop_duplicates(keep=\"first\",subset=duplicate_identifier_column)\n",
    "        \n",
    "        z.to_csv(f\"./duplicate_analysis/{name}.csv\",index=False)\n",
    "        with open(\"removal-numbers.txt\",\"a\") as f:\n",
    "            f.write(text)\n",
    "        print(f\"Generated: {name}\")\n",
    "\n",
    "    # Made to work with a single file and a list of files\n",
    "    def read_through_files(files):\n",
    "\n",
    "        if type(files) is str:\n",
    "            name=result_name\n",
    "            name=name.replace(\".xlsx\",\"\")\n",
    "            name=name.replace(\".csv\",\"\")\n",
    "            if files.find(\".csv\")!=-1:\n",
    "                df=pd.read_csv(files,delimiter=\",\")\n",
    "                organize(df,name)\n",
    "            else:\n",
    "                sheets = pd.ExcelFile(files).sheet_names\n",
    "                if len(sheets)>1:\n",
    "                    for sheet in sheets:\n",
    "                        if sheet != \".\":\n",
    "                            name=sheet\n",
    "                            df=pd.read_excel(files,sheet_name=sheet)\n",
    "                            organize(df,name)\n",
    "                else:\n",
    "                    for sheet in sheets:\n",
    "                        if sheet != \".\":\n",
    "                            #name=sheet\n",
    "                            df=pd.read_excel(files,sheet_name=sheet)\n",
    "                            organize(df,name)\n",
    "        else:\n",
    "            for file in files:\n",
    "                name=str(file).replace(path_to_files,\"\")\n",
    "                name=name.replace(\".xlsx\",\"\")\n",
    "                name=name.replace(\".csv\",\"\")\n",
    "                if file.find(\".csv\")!=-1:\n",
    "                    df=pd.read_csv(file,delimiter=\",\")\n",
    "                    organize(df,name)\n",
    "                else:   \n",
    "                    sheets = pd.ExcelFile(file).sheet_names\n",
    "                    if len(sheets)>1:\n",
    "                        for sheet in sheets:\n",
    "                            if sheet != \".\":\n",
    "                                name=sheet\n",
    "                                df=pd.read_excel(file,sheet_name=sheet)\n",
    "                                organize(df,name)\n",
    "                    else:\n",
    "                        for sheet in sheets:\n",
    "                            if sheet != \".\":\n",
    "                                #name=sheet\n",
    "                                df=pd.read_excel(file,sheet_name=sheet)\n",
    "                                organize(df,name)\n",
    "\n",
    "    read_through_files(files=files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run to execute\n",
    "###### Equivalent to if __name__ == __main__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Cholestasiss\n",
      "Generated: Filtered Cholestasiss\n",
      "Cholestasis\n",
      "Generated: Cholestasis\n",
      "Filtered Liver Injury\n",
      "Generated: Filtered Liver Injury\n",
      "Liver Injury\n",
      "Generated: Liver Injury\n",
      "Filtered cholestatic Jaundice\n",
      "Generated: Filtered cholestatic Jaundice\n",
      "Cholestatic Jaundice\n",
      "Generated: Cholestatic Jaundice\n",
      "Filtered Jaundice\n",
      "Generated: Filtered Jaundice\n",
      "Jaundice\n",
      "Generated: Jaundice\n",
      "Filtered Hyperbilirubinemia\n",
      "Generated: Filtered Hyperbilirubinemia\n",
      "Hyperbilirrubinemia\n",
      "Generated: Hyperbilirrubinemia\n",
      "Filtered Hepatotoxicity\n",
      "Generated: Filtered Hepatotoxicity\n",
      "Filtered Hepatomegaly\n",
      "Generated: Filtered Hepatomegaly\n",
      "Hepatomegaly\n",
      "Generated: Hepatomegaly\n",
      "Filtered HepatoCellular injury\n",
      "Generated: Filtered HepatoCellular injury\n",
      "Hepatocellular injury\n",
      "Generated: Hepatocellular injury\n",
      "Filtered HepatoBiliary disorder\n",
      "Generated: Filtered HepatoBiliary disorder\n",
      "Filtered Hepatic necrosis\n",
      "Generated: Filtered Hepatic necrosis\n",
      "Filtered Abnormal Hepatic Fun \n",
      "Generated: Filtered Abnormal Hepatic Fun \n",
      "Filtered Hepatic Failure\n",
      "Generated: Filtered Hepatic Failure\n",
      "Filtered Cholelitiasis\n",
      "Generated: Filtered Cholelitiasis\n",
      "Filtered Cholecystitis\n",
      "Generated: Filtered Cholecystitis\n",
      "Filtered Autoimune hepatitis\n",
      "Generated: Filtered Autoimune hepatitis\n",
      "Filtered Hepatic Cirrhosis\n",
      "Generated: Filtered Hepatic Cirrhosis\n",
      "Filtered Hepatitis\n",
      "Generated: Filtered Hepatitis\n",
      "Filtered Acute Hepatitis\n",
      "Generated: Filtered Acute Hepatitis\n",
      "Filtered Cholestatic Hepatitis\n",
      "Generated: Filtered Cholestatic Hepatitis\n",
      "Filtered Fulminant Hepatitis\n",
      "Generated: Filtered Fulminant Hepatitis\n",
      "Filtered Toxic Hepatitis\n",
      "Generated: Filtered Toxic Hepatitis\n",
      "Filtered Hepatic Steatosis\n",
      "Generated: Filtered Hepatic Steatosis\n",
      "Hepatic Steatosis\n",
      "Generated: Hepatic Steatosis\n"
     ]
    }
   ],
   "source": [
    "# Execute everything\n",
    "main(s_file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
