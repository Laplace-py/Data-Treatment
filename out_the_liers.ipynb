{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "#from IPython.display import display\n",
    "\n",
    "# Made by Henric Pietro Vicente Gil please credit me in your work :) \n",
    "# henricgil@discente.ufg.br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# This cell defines the location of the files, \n",
    "\n",
    "# path_to_files may be a folder where multiple files are;\n",
    "\n",
    "# file_list is a list of all the files in the folder provided in path_to_files;\n",
    "\n",
    "# s_file represents the file(s) to be read, can be either a list or a string\n",
    "\n",
    "# uncomment the part that you will use, comment the part you wont\n",
    "\"\"\"\n",
    "\n",
    "# Points to a file ./myfolder/example.xlsx or to a folder c:\\\\my\\\\folder\\\\where\\\\my\\\\\\files\\\\are\n",
    "path_to_files = r'D:\\Projetos academicos\\Labmol\\Code\\Data Treatment\\data\\cli'#r'D:\\Projetos academicos\\Labmol\\Code\\Data\\My_data\\Pre Clinical Data\\Legacy_Data\\Filtered_Clinical_Data.xlsx'\n",
    "# if its a single file pass its name\n",
    "result_name = \"LOAEL_clinical_hepato\"\n",
    "try:\n",
    "    os.mkdir(\"./data\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "#### To get from a directory\n",
    "\n",
    "try:\n",
    "    file_list = [f for f in os.listdir(path_to_files) if os.path.isfile(f\"{path_to_files}\\\\{f}\")]\n",
    "    s_file = [f\"{path_to_files}\\\\{file}\" for file in file_list]\n",
    "\n",
    "#### To get from a path\n",
    "except NotADirectoryError:\n",
    "    s_file = path_to_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Defines the necessary variables used all through out the code\n",
    "\n",
    "# duplicate_identifier_column is the collumn that identifies the duplicates in your code\n",
    "\n",
    "# values_col defines the column where your dose/lc50/ic50... values are\n",
    "\n",
    "# max_z_score is the z value used to separate the outliers from non outliers\n",
    "\n",
    "# convert_to_p despite the name, this bool conditions the result into a -log(result) or pResult\n",
    "\n",
    "# convert_measure bool that conditions if you need to convert measurements, also eliminates impossible values\n",
    "\"\"\"\n",
    "duplicate_identifier_column = 'final_smiles_stand'\n",
    "differenciator = \"Clinical_\"\n",
    "values_col = \"Dose\"\n",
    "max_z_score = 0.3\n",
    "standardize_mol = False\n",
    "convert_to_p = False # p = -log(measure)\n",
    "convert_measure = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize thy molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "from rdkit.Chem.rdmolops import FindPotentialStereo\n",
    "from chembl_structure_pipeline import standardizer \n",
    "from rdkit.Chem.SaltRemover import SaltRemover\n",
    "\n",
    "def standardize(df:pd.DataFrame,name):\n",
    "    name_smiles = \"Chemical Structure\"\n",
    "    METALS = [\"B\",\"Li\",\"Na\",\"K\",\"Rb\",\"Cs\",\"Be\",\"Mg\",\"Ca\",\"Sr\",\"Ba\",\"Ra\",\"Sc\",\"Ti\",\"V\",\"Cr\",\"Mn\",\"Fe\",\"Co\",\"Ni\",\"Cu\",\"Zn\",\"Al\",\"Ga\",\"Y\",\"Zr\",\"Nb\",\"Mo\",\"Tc\",\"Ru\",\"Rh\",\"Pd\",\"Ag\",\"Cd\",\"In\",\"Sn\",\"Hf\",\"Ta\",\"W\",\"Re\",\"Os\",\"Ir\",\"Pt\",\"Au\",\"Hg\",\"Tl\",\"Pb\",\"Bi\"]\n",
    "    #NON_METALS = [\"Br\",\"Cl\",\"F\",\"Br-\",\"Cl-\",\"F-\",\"Br--\",\"Cl--\",\"F--\",\"B+\",\"Cl+\",\"F+\",\"Br++\",\"Cl++\",\"F++\",\"O\",\"O-\",\"O--\",\"O+\",\"O++\"]\n",
    "    ORGANIC_SALTS = [\"OC( = O)\\C = C/C(O) = O\",\"C1CCCCC1[NH]C1CCCCC1\",\"OC( = O)C(O)C(O)C( = O)O\",\"OS(O)( = O) = O\",\"OC( = O)C( = O)O\",\"OC( = O)C = CC( = O)O\",\"FC(F)(F)C( = O)O\",\"[CH3]C( = O)O\",\"[N]( = O)(O)O\",\"[P]( = O)(O)(O)O\",\"[P](F)(F)(F)(F)(F)F\",\"[S]( = O)( = O)(O)O\",\"[CH3][S]( = O)( = O)(O)\",\"c1cc([CH3])ccc1[S]( = O)( = O)(O)\"]\n",
    "    #df.dropna(subset = name_smiles,how = \"any\",axis = 0,inplace = True)\n",
    "    fonte = \"Source\"\n",
    "    removals = []\n",
    "    \n",
    "    def remove_non_str(df:pd.DataFrame):\n",
    "            invalids = 0\n",
    "            for i,smi in enumerate(df[name_smiles]):\n",
    "                    if type(smi) is not str:\n",
    "                        invalids+= 1\n",
    "                        #df.drop(index = i,axis = 0 ,inplace = True)\n",
    "                    # try:\n",
    "                    #     smiles = df[name_smiles][i]\n",
    "                    #     m = Chem.MolFromSmiles(smiles)\n",
    "                    #     if m is None:\n",
    "                    #         invalids+= 1\n",
    "                    #         df.drop(index = i,axis = 0 ,inplace = True)\n",
    "                    # except TypeError:\n",
    "                    #     invalids+= 1\n",
    "                    #     df.drop(index = i,axis = 0 ,inplace = True)\n",
    "                        nf = df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                        removals.append([f\"Index: {i}\",nf[0],nf[1],\"Empty or not an smiles entry\"])\n",
    "                        df.drop(index = i,axis = 0 ,inplace = True)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "            return df,invalids\n",
    "\n",
    "    def remove_invalid(df:pd.DataFrame):\n",
    "        invalids = 0\n",
    "        for i,smi in enumerate(df[name_smiles]):\n",
    "            #if type(smi) is not str:    \n",
    "            try:\n",
    "                m = Chem.MolFromSmiles(smi)\n",
    "                if m is None:\n",
    "                    invalids+= 1\n",
    "                    nf = df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                    removals.append([nf[0],nf[1],\"invalid\"])\n",
    "                    df.drop(index = i,axis = 0 ,inplace = True)\n",
    "            except TypeError:\n",
    "                    invalids+= 1\n",
    "                    nf = df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                    removals.append([nf[0],nf[1],\"invalid\"])\n",
    "                    df.drop(index = i,axis = 0 ,inplace = True)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "            return df,invalids\n",
    "\n",
    "    def remove_metals(df:pd.DataFrame):\n",
    "        #badAtoms = Chem.MolFromSmarts('[!$([#1,#3,#11,#19,#4,#12,#20,#5,#6,#14,#7,#15,#8,#16,#9,#17,#35,#53])]')\n",
    "        hm_metal = 0\n",
    "        hm_mixture = 0\n",
    "        for i,smiles in enumerate(df[name_smiles]):\n",
    "            #smiles = df[i]\n",
    "            if type(smiles) is str:\n",
    "                \"\"\"6\"\"\"\n",
    "                if smiles.find(\".\")!= -1:\n",
    "                    is_mixture = str(smiles).split(\".\")\n",
    "                    non_metal_index = []\n",
    "                    for n,fragment in enumerate(is_mixture):\n",
    "                        for metal in METALS:\n",
    "                            striped = fragment.strip(\"+-[] \")\n",
    "                            #print(len(striped))\n",
    "                            if len(striped)>2 and striped.find(metal)==-1:# and striped not in NON_METALS and striped not in METALS:\n",
    "                                    if n not in non_metal_index:\n",
    "                                        non_metal_index.append(n)\n",
    "                                    else:\n",
    "                                        continue\n",
    "                            else:\n",
    "                                continue\n",
    "                    #print(len(non_metal_index))\n",
    "                    try:\n",
    "                        if len(non_metal_index)>1: #and (is_mixture[non_metal_index[0]]).strip(\"-+[] \") not in NON_METALS and (is_mixture[non_metal_index[0]]).strip(\"-+[]\") not in METALS:\n",
    "                            subs = 0\n",
    "                            for sub in is_mixture:\n",
    "                                if sub not in ORGANIC_SALTS:\n",
    "                                    subs+= 1\n",
    "                            if subs>1:\n",
    "                                nf = df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                                removals.append([f\"Index: {i}\",nf[0],nf[1],\"Mixture\"])\n",
    "                                df.drop(index = i,axis = 0,inplace = True)\n",
    "                                hm_mixture+= 1\n",
    "                            else:\n",
    "                                df.loc[i,name_smiles] = is_mixture[subs]\n",
    "                                \n",
    "                        elif len(non_metal_index)==1:\n",
    "\n",
    "                            df.loc[i,name_smiles] = is_mixture[non_metal_index[0]]\n",
    "                        \n",
    "                        elif len(non_metal_index)==0:\n",
    "                            hm_metal+= 1\n",
    "                            nf = df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                            removals.append([f\"Index: {i}\",nf[0],nf[1],\"Salt or metal\"])\n",
    "                            df.drop(index = i,axis = 0,inplace = True)\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "                else:\n",
    "                    try:\n",
    "                        for metal in METALS:\n",
    "                            m = smiles.find(metal)\n",
    "                            if m!= -1 and smiles[m+1] !=  \"r\":\n",
    "                                hm_metal+= 1\n",
    "                                nf = df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                                removals.append([f\"Index: {i}\",nf[0],nf[1],\"organometal\"])\n",
    "                                df.drop(index = i,axis = 0,inplace = True)\n",
    "                                break\n",
    "                    except KeyError:\n",
    "                        continue    \n",
    "        df.reset_index(drop = True, inplace = True)\n",
    "                            \n",
    "        #df.reset_index(drop = True, inplace = True)                    \n",
    "        return df,hm_metal,hm_mixture\n",
    "\n",
    "    def no_stereoisomer_info(df:pd.DataFrame):\n",
    "        mols = []\n",
    "        for smi in df[name_smiles]:\n",
    "            smi = str(smi).replace(\"@\",\"\")\n",
    "            mols.append(smi)\n",
    "        no_stereoisomer = pd.DataFrame(mols, columns = [\"no_stereoisomer\"])\n",
    "        df_stereoisomer = df.join(no_stereoisomer)\n",
    "        return df_stereoisomer\n",
    "\n",
    "    # Removes stereochemistry info and adds it to \"no_stereo\"\n",
    "    def chemblStandardizer(df:pd.DataFrame):\n",
    "        mols = [Chem.MolFromSmiles(smile) for smile in df[name_smiles] if smile is str]\n",
    "        invalids = 0\n",
    "        for i,mol in enumerate(mols):\n",
    "            try:\n",
    "                smiles = Chem.MolToSmiles(standardizer.standardize_mol(mol))\n",
    "                df.loc[i,name_smiles] = smiles    \n",
    "            except:\n",
    "                try:\n",
    "                    nf = df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                    removals.append([f\"Index: {i}\",nf[0],nf[1],\"Even Landrum couldnt do it\"])\n",
    "                    df.drop(index = i,axis = 0 ,inplace = True)\n",
    "                    invalids+= 1\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        df.reset_index(drop = True, inplace = True)\n",
    "        return df,invalids\n",
    "\n",
    "    def standardize_with_and_out_stereo(df) -> pd.DataFrame:\n",
    "        df,invalids = remove_non_str(df)\n",
    "        df,real_invalids = chemblStandardizer(df)\n",
    "        df,hm_metal,hm_mixture = remove_metals(df)\n",
    "        df = no_stereoisomer_info(df)\n",
    "        invalids = invalids+real_invalids\n",
    "        removals_df = pd.DataFrame(removals,columns = [\"Index on that table\",fonte,name_smiles,\"What Happened\"],index = range(len(removals)))\n",
    "        removals_df.to_csv(f\"./data/{name}_Removals.csv\")\n",
    "        return df,hm_metal,hm_mixture,invalids#,norm,neutr,taut\n",
    "\n",
    "    \n",
    "    #generates mol from smiles\n",
    "    \n",
    "    \n",
    "    return standardize_with_and_out_stereo(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO NOT RUN UNLESS YOUR DATA CONTAINS NULL CHARS ########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######### DO NOT RUN UNLESS YOUR DATA CONTAINS NULL CHARS ################\n",
    "\n",
    "for file in s_file:        \n",
    "        with open(file,\"r\") as f:\n",
    "                a = f.read()\n",
    "\n",
    "        a = a.replace(\"\\x00\",\"\")\n",
    "        \n",
    "        with open(file,\"w\") as f:\n",
    "                f.write(a)\n",
    "        # df = pd.read_csv(file,delimiter = \",\")\n",
    "        # print(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DONT RUN UNLESS YOUR FILES HAVE SOME COMPATIBILITY ISSUES #######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DONT RUN UNLESS YOUR FILES HAVE SOME COMPATIBILITY ISSUES #######\n",
    "if type(s_file) is not str:\n",
    "    for file in s_file:\n",
    "        name = str(file).replace(path_to_files,\"\")\n",
    "        name = name.replace(\".csv\",\".xlsx\")\n",
    "        \n",
    "        df = pd.read_csv(file,delimiter = \",\")\n",
    "        df.to_excel(f\"temp_dataset/{name}\")\n",
    "\n",
    "path_to_files = \"./temp_dataset\"\n",
    "file_list = os.listdir(path_to_files)\n",
    "s_file = [f\"{path_to_files}\\\\{file}\" for file in file_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defintively run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.rdMolDescriptors import CalcMolFormula\n",
    "import re\n",
    "# e.g. cysteine\n",
    "#mol = Chem.MolFromSmiles(\"C([C@@H](C( = O)O)N)S\")\n",
    "#CalcMolFormula(mol)\n",
    "def remove_non_str(df:pd.DataFrame):\n",
    "            name_smiles = duplicate_identifier_column\n",
    "            invalids = 0\n",
    "            for i,smi in enumerate(df[name_smiles]):\n",
    "                    if type(smi) is not str:\n",
    "                        invalids+= 1\n",
    "                        #df.drop(index = i,axis = 0 ,inplace = True)\n",
    "                    # try:\n",
    "                    #     smiles = df[name_smiles][i]\n",
    "                    #     m = Chem.MolFromSmiles(smiles)\n",
    "                    #     if m is None:\n",
    "                    #         invalids+= 1\n",
    "                    #         df.drop(index = i,axis = 0 ,inplace = True)\n",
    "                    # except TypeError:\n",
    "                    #     invalids+= 1\n",
    "                    #     df.drop(index = i,axis = 0 ,inplace = True)\n",
    "                        #nf = df.loc[i,[name_smiles,fonte]].values.flatten().tolist()\n",
    "                        #removals.append([f\"Index: {i}\",nf[0],nf[1],\"Empty or not an smiles entry\"])\n",
    "                        df.drop(index = i,axis = 0 ,inplace = True)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "            return df#,invalids    \n",
    "def main(files):\n",
    "    \n",
    "    def get_mass(formula):\n",
    "\n",
    "        parts = re.findall(\"[A-Z][a-z]?|[0-9]+\", formula)\n",
    "        mass = 0\n",
    "\n",
    "        for index in range(len(parts)):\n",
    "            if parts[index].isnumeric():\n",
    "                continue\n",
    "\n",
    "            atom = Chem.Atom(parts[index])\n",
    "            multiplier = int(parts[index + 1]) if len(parts) > index + 1 and parts[index + 1].isnumeric() else 1\n",
    "            mass +=  atom.GetMass() * multiplier\n",
    "\n",
    "        return mass\n",
    "    \n",
    "    def isInt(i):\n",
    "        \"\"\"Check if it is an integer\"\"\"\n",
    "        try:\n",
    "            int(i)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def isFloat(f):\n",
    "        try:\n",
    "            float(f)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def convertTo_mg(df, column = values_col):\n",
    "        \"\"\"\n",
    "        Pass a pandas 'series like' (aka: df.column) of measurement strings, \n",
    "        convert the values into miligram numbers, \n",
    "        returns a list of lists with a number and the unit\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        micro = \"\\u00B5\"\n",
    "        measure = []\n",
    "\n",
    "        for dose in df.loc[:, column]:\n",
    "            # num = [n for n in number if isInt(n) or n==\".\"]\n",
    "            num = \"\"\n",
    "            unit = \"\"\n",
    "            nums = []\n",
    "            avg = 0\n",
    "            # Ensures it is not nan or None\n",
    "            if type(dose) is str:\n",
    "                for i, n in enumerate(dose):\n",
    "                    # Avoids unprecise entries\n",
    "                    if n in [\"<\", \">\"]:\n",
    "                        continue\n",
    "\n",
    "                    if isInt(n) or n == \".\" and num.find(\".\") == -1:\n",
    "                        num +=  n\n",
    "\n",
    "                    if isInt(n) == False:\n",
    "                        unit +=  n\n",
    "                        num = \"\"\n",
    "                    if n in [\",\", \"-\", \"\\\\\", \".\", \"/\"] and num.find(\".\") !=  0 and num !=  \"\":\n",
    "                        num.strip(' ,-\\\\/[]\"')\n",
    "                        nums.append(float(num))\n",
    "                        num = \"\"\n",
    "                    if len(nums) > 1 and \"\" not in nums:\n",
    "                        avg = np.mean(nums)\n",
    "\n",
    "                    elif len(nums) == 0 and num !=  \"\":\n",
    "                        avg = float(num)\n",
    "                # unit = [str(s) for s in number if isInt(s)==False]\n",
    "                measure.append([avg, str(unit).strip(\" -.\")])\n",
    "\n",
    "            elif type(dose) is float or type(dose) is int:\n",
    "                measure.append([dose, \"mg\"])\n",
    "        for i, m in enumerate(measure):\n",
    "            # print(m)\n",
    "            u = str(m[1])\n",
    "            n = m[0]\n",
    "\n",
    "            # if you want to use the strings that contain unit values uncomment the commented lines\n",
    "            if u.find(\"kg\") !=  -1 and u.find(\"mg\") == -1:\n",
    "                measure[i][0] = n*1_000_000\n",
    "                # measure[i][1] = str(measure[i][1]).replace(\"kg\",\"mg\")\n",
    "\n",
    "            # might be with special char\n",
    "            elif u.find(f\"{micro}g\") !=  -1 or unit.find(\"ug\") !=  -1:\n",
    "                measure[i][0] = n/1000\n",
    "                # measure[i][1] = str(measure[i][1]).replace(\"ug\",\"mg\")\n",
    "\n",
    "            elif u.find(\"cg\") !=  -1:\n",
    "                measure[i][0] = n*10\n",
    "                # measure[i][1] = str(measure[i][1]).replace(\"cg\",\"mg\")\n",
    "            if u.find(\"mg\") == 0:\n",
    "                measure[i][0] = n\n",
    "\n",
    "            if u.find(\"g\") == 0:\n",
    "                measure[i][0] = n*1000\n",
    "                # measure[i][1] = str(measure[i][1]).replace(\"g\",\"mg\")\n",
    "\n",
    "        solved_col = pd.Series(measure)\n",
    "\n",
    "        return solved_col\n",
    "    \n",
    "    # Method that calculates the standard deviation with a number list and the mean, but use np.std() instead\n",
    "    def stdCalculation(numList, mean):\n",
    "        n = len(numList)+1\n",
    "        soma = 0\n",
    "        for x in numList:\n",
    "            soma += (x-mean)**2\n",
    "        std = math.sqrt((soma)/n)\n",
    "        return std\n",
    "\n",
    "    # Method to calculate the z score for each number in a array of numbers, returns a list of z-scores of each number relevant to the array\n",
    "    def z_scorer(nums: list, mean: float or int, std: float or int):\n",
    "\n",
    "        z_scores = []\n",
    "        for x in nums:\n",
    "            z = (x-mean)/std\n",
    "            z_scores.append(z)\n",
    "        return z_scores\n",
    "\n",
    "    # Most of the action happens here\n",
    "    def idOutliers(df: pd.DataFrame, name_col: str = \"Drug\", value_col: str = \"Dose\", max_z: float = 1.8, convert_to_p: bool = True):\n",
    "        dict_rows = {}\n",
    "        means = {}\n",
    "        # Comment if you have empty values\n",
    "        df = df.dropna(axis = 0, how = \"all\")\n",
    "        \n",
    "        if convert_measure:\n",
    "            values = [float(num) for num,mg in df.loc[:, value_col]]\n",
    "           # print(values)\n",
    "        else:\n",
    "            values = [float(num) for num in df.loc[:, value_col]]\n",
    "        \n",
    "        names = [str(drugs) for drugs in df.loc[:, name_col]]# if type(drugs) is str]\n",
    "        mols = [Chem.MolFromSmiles(smi) for smi in names]\n",
    "        formulas = [CalcMolFormula(mol) for mol in mols if mol is not None]\n",
    "        for i, name in enumerate(names):\n",
    "            if name==\"\" or name==\"-\":\n",
    "                name = \"Empty\"\n",
    "                \n",
    "            if name not in dict_rows:\n",
    "                dict_rows[name] = []\n",
    "                \n",
    "                dict_rows[name].append(values[i])\n",
    "            else:\n",
    "                dict_rows[name].append(values[i])\n",
    "\n",
    "        for i,n in enumerate(dict_rows):\n",
    "            media = []\n",
    "            molw = get_mass(formulas[i])\n",
    "\n",
    "            if len(dict_rows[n]) > 1 and type(dict_rows[n]) is float:\n",
    "                means[n] = np.mean(dict_rows[n])\n",
    "\n",
    "                if dict_rows[n][0] != 0 and means[n]/dict_rows[n][0] !=  1:\n",
    "                    std = np.std(dict_rows[n])\n",
    "                else:\n",
    "                    std = 1\n",
    "\n",
    "                z = z_scorer(dict_rows[n], means[n], std)\n",
    "\n",
    "                for j, z_value in enumerate(z):\n",
    "                    if abs(z_value) <= max_z:\n",
    "                        media.append(dict_rows[n][j])\n",
    "\n",
    "                med = np.mean(media)\n",
    "                \n",
    "                # atrubutes where in the column specified is equal to the name of the current row, and replaces the value (dose) of that row\n",
    "                if convert_to_p:\n",
    "                    df.loc[df[name_col] == n, value_col] = -math.log10(med/molw)\n",
    "                else:\n",
    "                    df.loc[df[name_col] == n, value_col] = med/molw\n",
    "            else:\n",
    "                val = dict_rows[n][0]\n",
    "                #print(dict_rows[n])\n",
    "                if convert_to_p:\n",
    "                    if dict_rows[n][0] <=  0:\n",
    "                        df.loc[df[name_col] == n, value_col] = val\n",
    "                    else: \n",
    "                        df.loc[df[name_col] == n, value_col] = -math.log10(val/molw)\n",
    "                else:\n",
    "                    df.loc[df[name_col] == n, value_col] = val/molw\n",
    "                    \n",
    "        dups = len(values) - len(dict_rows.keys())\n",
    "        tl = len(dict_rows.keys())\n",
    "        return df,dups,tl\n",
    "    \n",
    "    # computes in the order necessary to generate the dataframes\n",
    "    def organize(df,name):\n",
    "        # read\n",
    "        print(name)    \n",
    "        # convert?\n",
    "        if convert_measure:\n",
    "            new_doses = convertTo_mg(df, values_col)\n",
    "            df[values_col] = new_doses\n",
    "        # generate\n",
    "        df = remove_non_str(df)\n",
    "        if standardize_mol:\n",
    "            df,hm_metal,hm_mixture,invalids = standardize(df,name)\n",
    "            text = f\"Table: {name}: \\n Removed metals: {hm_metal} \\t Removed mixtures: {hm_mixture} \\t Invalids removed: {invalids} \\t Removed duplicates: {dups} \\t Total Lenght: {total_lenght} \\n \\n\"\n",
    "        else:\n",
    "            text = f\"Table: {name}\" \n",
    "        \n",
    "        z,dups,total_lenght = idOutliers(df, name_col = duplicate_identifier_column, value_col = values_col, max_z = max_z_score, convert_to_p = convert_to_p)\n",
    "        \n",
    "        text += f\"\\t Removed Duplicates: {dups} \\t Total Lenght: {total_lenght} \\n \\n\"\n",
    "        \n",
    "        z = z.drop_duplicates(keep = \"first\",subset = duplicate_identifier_column)\n",
    "        \n",
    "        if z.shape[0] > 50 :\n",
    "            z.to_csv(f\"./duplicate_analysis/{differenciator}{name}.csv\",index = False)\n",
    "        else:\n",
    "            print(f\"|With {total_lenght}| this |endpoint {name}|  had less than 50 entries  \")\n",
    "        \n",
    "        with open(f\"{result_name}.txt\",\"a\") as f:\n",
    "            f.write(text)\n",
    "        print(f\"Generated: {name}\")\n",
    "\n",
    "    # Made to work with a single file and a list of files\n",
    "    def read_through_files(files):\n",
    "\n",
    "        if type(files) is str:\n",
    "            name = result_name\n",
    "            name = name.replace(\".xlsx\",\"\")\n",
    "            name = name.replace(\".csv\",\"\")\n",
    "            if files.find(\".csv\")!= -1:\n",
    "                df = pd.read_csv(files, delimiter = \",\") #encoding = 'latin-1')\n",
    "                organize(df,name)\n",
    "            else:\n",
    "                sheets = pd.ExcelFile(files).sheet_names\n",
    "                if len(sheets)>1:\n",
    "                    for sheet in sheets:\n",
    "                        if sheet !=  \".\":\n",
    "                            name = sheet\n",
    "                            df = pd.read_excel(files,sheet_name = sheet)\n",
    "                            organize(df,name)\n",
    "                else:\n",
    "                    for sheet in sheets:\n",
    "                        if sheet !=  \".\":\n",
    "                            #name = sheet\n",
    "                            df = pd.read_excel(files,sheet_name = sheet)\n",
    "                            organize(df,name)\n",
    "        else:\n",
    "            for file in files:\n",
    "                name = str(file).replace(path_to_files,\"\")\n",
    "                name = name.strip(\"/\\\\\")\n",
    "                name = name.replace(\".xlsx\",\"\")\n",
    "                name = name.replace(\".csv\",\"\")\n",
    "                if file.find(\".csv\") !=  -1:\n",
    "                    df = pd.read_csv(file,delimiter = \",\")#,encoding = 'latin-1')\n",
    "                    organize(df,name)\n",
    "                else:   \n",
    "                    sheets = pd.ExcelFile(file).sheet_names\n",
    "                    if len(sheets)>1:\n",
    "                        for sheet in sheets:\n",
    "                            if sheet !=  \".\":\n",
    "                                name = sheet\n",
    "                                df = pd.read_excel(file,sheet_name = sheet)\n",
    "                                organize(df,name)\n",
    "                    else:\n",
    "                        for sheet in sheets:\n",
    "                            if sheet !=  \".\":\n",
    "                                #name = sheet\n",
    "                                df = pd.read_excel(file,sheet_name = sheet)\n",
    "                                organize(df,name)\n",
    "\n",
    "    read_through_files(files = files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run to execute\n",
    "###### Equivalent to if __name__ == __main__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_Abnormal Hepatic Fun \n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'molw' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projetos academicos\\Labmol\\Code\\Data Treatment\\out_the_liers.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000014?line=0'>1</a>\u001b[0m \u001b[39m# Execute everything\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000014?line=1'>2</a>\u001b[0m main(s_file)\n",
      "\u001b[1;32md:\\Projetos academicos\\Labmol\\Code\\Data Treatment\\out_the_liers.ipynb Cell 11'\u001b[0m in \u001b[0;36mmain\u001b[1;34m(files)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=295'>296</a>\u001b[0m                             df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(file,sheet_name \u001b[39m=\u001b[39m sheet)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=296'>297</a>\u001b[0m                             organize(df,name)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=298'>299</a>\u001b[0m read_through_files(files \u001b[39m=\u001b[39;49m files)\n",
      "\u001b[1;32md:\\Projetos academicos\\Labmol\\Code\\Data Treatment\\out_the_liers.ipynb Cell 11'\u001b[0m in \u001b[0;36mmain.<locals>.read_through_files\u001b[1;34m(files)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=280'>281</a>\u001b[0m \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m!=\u001b[39m  \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=281'>282</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file,delimiter \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m#,encoding = 'latin-1')\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=282'>283</a>\u001b[0m     organize(df,name)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=283'>284</a>\u001b[0m \u001b[39melse\u001b[39;00m:   \n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=284'>285</a>\u001b[0m     sheets \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mExcelFile(file)\u001b[39m.\u001b[39msheet_names\n",
      "\u001b[1;32md:\\Projetos academicos\\Labmol\\Code\\Data Treatment\\out_the_liers.ipynb Cell 11'\u001b[0m in \u001b[0;36mmain.<locals>.organize\u001b[1;34m(df, name)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=232'>233</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=233'>234</a>\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTable: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=235'>236</a>\u001b[0m z,dups,total_lenght \u001b[39m=\u001b[39m idOutliers(df, name_col \u001b[39m=\u001b[39;49m duplicate_identifier_column, value_col \u001b[39m=\u001b[39;49m values_col, max_z \u001b[39m=\u001b[39;49m max_z_score, convert_to_p \u001b[39m=\u001b[39;49m convert_to_p)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=237'>238</a>\u001b[0m text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m Removed Duplicates: \u001b[39m\u001b[39m{\u001b[39;00mdups\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m Total Lenght: \u001b[39m\u001b[39m{\u001b[39;00mtotal_lenght\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=239'>240</a>\u001b[0m z \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39mdrop_duplicates(keep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m\"\u001b[39m,subset \u001b[39m=\u001b[39m duplicate_identifier_column)\n",
      "\u001b[1;32md:\\Projetos academicos\\Labmol\\Code\\Data Treatment\\out_the_liers.ipynb Cell 11'\u001b[0m in \u001b[0;36mmain.<locals>.idOutliers\u001b[1;34m(df, name_col, value_col, max_z, convert_to_p)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=211'>212</a>\u001b[0m                 df\u001b[39m.\u001b[39mloc[df[name_col] \u001b[39m==\u001b[39m n, value_col] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mmath\u001b[39m.\u001b[39mlog10(val\u001b[39m/\u001b[39mmolw)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=212'>213</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=213'>214</a>\u001b[0m             df\u001b[39m.\u001b[39mloc[df[name_col] \u001b[39m==\u001b[39m n, value_col] \u001b[39m=\u001b[39m val\u001b[39m/\u001b[39mmolw\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=215'>216</a>\u001b[0m dups \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(values) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(dict_rows\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projetos%20academicos/Labmol/Code/Data%20Treatment/out_the_liers.ipynb#ch0000012?line=216'>217</a>\u001b[0m tl \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dict_rows\u001b[39m.\u001b[39mkeys())\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'molw' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Execute everything\n",
    "main(s_file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fa495dfb2e0dadd8ed0afe6080159ac5bdc526ac154811e8f369ccca6201803"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DLModels')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
