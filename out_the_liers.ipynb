{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "from rdkit.Chem.rdmolops import FindPotentialStereo\n",
    "#from IPython.display import display\n",
    "\n",
    "# Made by Henric Pietro Vicente Gil please credit me in your work :) \n",
    "# henricgil@discente.ufg.br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# This cell defines the location of the files, \n",
    "\n",
    "# path_to_files may be a folder where multiple files are;\n",
    "\n",
    "# file_list is a list of all the files in the folder provided in path_to_files;\n",
    "\n",
    "# s_file represents the file(s) to be read, can be either a list or a string\n",
    "\n",
    "# uncomment the part that you will use, comment the part you wont\n",
    "\"\"\"\n",
    "\n",
    "# Points to a file ./myfolder/example.xlsx or to a folder c:\\\\my\\\\folder\\\\where\\\\my\\\\\\files\\\\are\n",
    "path_to_files = \"D:\\\\Projetos academicos\\\\Labmol\\\\Code\\\\Data\\\\My_data\\\\Pre Clinical Data\\\\Bundled_Data\\\\results\"\n",
    "# if its a single file pass its name\n",
    "result_name=\"Resultado_exemplo\"\n",
    "try:\n",
    "    os.mkdir(\"./data\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "#### To get from a directory\n",
    "\n",
    "file_list=os.listdir(path_to_files)\n",
    "s_file = [f\"{path_to_files}\\\\{file}\" for file in file_list]\n",
    "\n",
    "#### To get from a path\n",
    "\n",
    "#s_file=path_to_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Defines the necessary variables used all through out the code\n",
    "\n",
    "# duplicate_identifier_column is the collumn that identifies the duplicates in your code\n",
    "\n",
    "# values_col defines the column where your dose/lc50/ic50... values are\n",
    "\n",
    "# max_z_score is the z value used to separate the outliers from non outliers\n",
    "\n",
    "# convert_to_p despite the name, this bool conditions the result into a -log(result) or pResult\n",
    "\n",
    "# convert_measure bool that conditions if you need to convert measurements, also eliminates impossible values\n",
    "\"\"\"\n",
    "duplicate_identifier_column = \"Chemical Structure\"\n",
    "values_col = \"Dose\"\n",
    "max_z_score = 3\n",
    "convert_to_p = True # p = -log(measure)\n",
    "convert_measure = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize thy molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_smiles=\"Chemical Structure\"\n",
    "\n",
    "def remove_invalid(df):\n",
    "        for i in df.index:\n",
    "            try:\n",
    "                smiles = df[name_smiles][i]\n",
    "                m = Chem.MolFromSmiles(smiles)\n",
    "            except:\n",
    "                df.drop(i, inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "\n",
    "def remove_metals(df):\n",
    "    badAtoms = Chem.MolFromSmarts('[!$([#1,#3,#11,#19,#4,#12,#20,#5,#6,#14,#7,#15,#8,#16,#9,#17,#35,#53])]')\n",
    "    mols = []\n",
    "    for i in df.index:\n",
    "        smiles = df[name_smiles][i]\n",
    "        m = Chem.MolFromSmiles(smiles)\n",
    "        try:\n",
    "            if m.HasSubstructMatch(badAtoms):\n",
    "                df.drop(i, inplace=True)\n",
    "        except:\n",
    "            df.drop(i, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def normalize_groups(df):\n",
    "    mols = []\n",
    "    for smi in df[name_smiles]:\n",
    "        m = Chem.MolFromSmiles(smi,sanitize=True)\n",
    "        m2 = rdMolStandardize.Normalize(m)\n",
    "        smi = Chem.MolToSmiles(m2,kekuleSmiles=True)\n",
    "        mols.append(smi)\n",
    "    norm = pd.Series(mols)\n",
    "    df[name_smiles] = norm\n",
    "    #df_normalized = df.join(norm)\n",
    "    return df\n",
    "\n",
    "def neutralize(df):\n",
    "    uncharger = rdMolStandardize.Uncharger()\n",
    "    mols = []\n",
    "    for smi in df[name_smiles]:\n",
    "        m = Chem.MolFromSmiles(smi,sanitize=True)\n",
    "        m2 = uncharger.uncharge(m)\n",
    "        smi = Chem.MolToSmiles(m2,kekuleSmiles=True)\n",
    "        mols.append(smi)\n",
    "    #neutral = pd.DataFrame(mols, columns=[name_smiles])\n",
    "    #df_neutral = df.join(neutral)\n",
    "    norm = pd.Series(mols)\n",
    "    df[name_smiles] = norm\n",
    "    return df\n",
    "    \n",
    "def no_mixture(df):\n",
    "    mols = []\n",
    "    for smi in df[name_smiles]:\n",
    "        m = Chem.MolFromSmiles(smi,sanitize = True)\n",
    "        m2 = rdMolStandardize.FragmentParent(m)\n",
    "        smi = Chem.MolToSmiles(m2,kekuleSmiles=True)\n",
    "        mols.append(smi)\n",
    "    #no_mixture = pd.DataFrame(mols, columns=[name_smiles])\n",
    "    #df_no_mixture = df.join(no_mixture)\n",
    "    norm = pd.Series(mols)\n",
    "    df[name_smiles] = norm\n",
    "    return df\n",
    "\n",
    "def canonical_tautomer(df):\n",
    "    te = rdMolStandardize.TautomerEnumerator()\n",
    "    mols = []\n",
    "    for smi in df[name_smiles]:\n",
    "        m = Chem.MolFromSmiles(smi,sanitize=True)\n",
    "        m2 = te.Canonicalize(m)\n",
    "        smi = Chem.MolToSmiles(m2,kekuleSmiles=True)\n",
    "        mols.append(smi)\n",
    "    # canonical_tautomer = pd.DataFrame(mols, columns=[name_smiles])\n",
    "    # df_canonical_tautomer = df.join(canonical_tautomer)\n",
    "    norm = pd.Series(mols)\n",
    "    df[name_smiles] = norm\n",
    "    return df\n",
    "\n",
    "def no_stereoisomer_info(df):\n",
    "    mols = []\n",
    "    for smi in df[name_smiles]:\n",
    "        smi = str(smi).replace(\"@\",\"\")\n",
    "        mols.append(smi)\n",
    "    # no_stereoisomer = pd.DataFrame(mols, columns=[name_smiles])\n",
    "    # df_stereoisomer = df.join(no_stereoisomer)\n",
    "    norm = pd.Series(mols)\n",
    "    df[name_smiles] = norm\n",
    "    return df\n",
    "# Removes stereochemistry info and adds it to \"no_stereo\"\n",
    "def standardize_with_and_out_stereo(df) -> pd.DataFrame:\n",
    "    df=remove_invalid(df)\n",
    "    df=remove_metals(df)\n",
    "    df=normalize_groups(df)\n",
    "    df=neutralize(df)\n",
    "    df=no_mixture(df)\n",
    "    df=canonical_tautomer(df)\n",
    "    df=no_stereoisomer_info(df)\n",
    "    return df\n",
    "\n",
    "def standardize_with_stereo(df) -> pd.DataFrame:\n",
    "    df=remove_invalid(df)\n",
    "    df=remove_metals(df)\n",
    "    df=normalize_groups(df)\n",
    "    df=neutralize(df)\n",
    "    df=no_mixture(df)\n",
    "    df=canonical_tautomer(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DO NOT RUN UNLESS YOUR DATA CONTAINS NULL CHARS ########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######### DO NOT RUN UNLESS YOUR DATA CONTAINS NULL CHARS ################\n",
    "\n",
    "for file in s_file:        \n",
    "        with open(file,\"r\") as f:\n",
    "                a=f.read()\n",
    "\n",
    "        a=a.replace(\"\\x00\",\"\")\n",
    "        \n",
    "        with open(file,\"w\") as f:\n",
    "                f.write(a)\n",
    "        # df=pd.read_csv(file,delimiter=\",\")\n",
    "        # print(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DONT RUN UNLESS YOUR FILES HAVE SOME COMPATIBILITY ISSUES #######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DONT RUN UNLESS YOUR FILES HAVE SOME COMPATIBILITY ISSUES #######\n",
    "if type(s_file) is not str:\n",
    "    for file in s_file:\n",
    "        name=str(file).replace(path_to_files,\"\")\n",
    "        name=name.replace(\".csv\",\".xlsx\")\n",
    "        \n",
    "        df=pd.read_csv(file,delimiter=\",\")\n",
    "        df.to_excel(f\"temp_dataset/{name}\")\n",
    "\n",
    "path_to_files = \"./temp_dataset\"\n",
    "file_list=os.listdir(path_to_files)\n",
    "s_file = [f\"{path_to_files}\\\\{file}\" for file in file_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defintively run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(files):\n",
    "    \n",
    "    def isInt(i):\n",
    "        \"\"\"Check if it is an integer\"\"\"\n",
    "        try:\n",
    "            int(i)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def isFloat(f):\n",
    "        try:\n",
    "            float(f)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def convertTo_mg(df, column=values_col):\n",
    "        \"\"\"\n",
    "        Pass a pandas 'series like' (aka: df.column) of measurement strings, \n",
    "        convert the values into miligram numbers, \n",
    "        returns a list of lists with a number and the unit\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        micro = \"\\u00B5\"\n",
    "        measure = []\n",
    "\n",
    "        for dose in df.loc[:, column]:\n",
    "            # num=[n for n in number if isInt(n) or n==\".\"]\n",
    "            num = \"\"\n",
    "            unit = \"\"\n",
    "            nums = []\n",
    "            avg = 0\n",
    "            # Ensures it is not nan or None\n",
    "            if type(dose) is str:\n",
    "                for i, n in enumerate(dose):\n",
    "                    # Avoids unprecise entries\n",
    "                    if n in [\"<\", \">\"]:\n",
    "                        continue\n",
    "\n",
    "                    if isInt(n) or n == \".\" and num.find(\".\") == -1:\n",
    "                        num += n\n",
    "\n",
    "                    if isInt(n) == False:\n",
    "                        unit += n\n",
    "                        num = \"\"\n",
    "                    if n in [\",\", \"-\", \"\\\\\", \".\", \"/\"] and num.find(\".\") != 0 and num != \"\":\n",
    "                        num.strip(\" ,-\\\\/\")\n",
    "                        nums.append(float(num))\n",
    "                        num = \"\"\n",
    "                    if len(nums) > 1 and \"\" not in nums:\n",
    "                        avg = np.mean(nums)\n",
    "\n",
    "                    elif len(nums) == 0 and num != \"\":\n",
    "                        avg = float(num)\n",
    "                # unit=[str(s) for s in number if isInt(s)==False]\n",
    "                measure.append([avg, str(unit).strip(\" -.\")])\n",
    "\n",
    "            elif type(dose) is float or type(dose) is int:\n",
    "                measure.append([dose, \"mg\"])\n",
    "        for i, m in enumerate(measure):\n",
    "            # print(m)\n",
    "            u = str(m[1])\n",
    "            n = m[0]\n",
    "\n",
    "            # if you want to use the strings that contain unit values uncomment the commented lines\n",
    "            if u.find(\"kg\") != -1 and u.find(\"mg\") == -1:\n",
    "                measure[i][0] = n*1_000_000\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"kg\",\"mg\")\n",
    "\n",
    "            # might be with special char\n",
    "            elif u.find(f\"{micro}g\") != -1 or unit.find(\"ug\") != -1:\n",
    "                measure[i][0] = n/1000\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"ug\",\"mg\")\n",
    "\n",
    "            elif u.find(\"cg\") != -1:\n",
    "                measure[i][0] = n*10\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"cg\",\"mg\")\n",
    "            if u.find(\"mg\") == 0:\n",
    "                measure[i][0] = n\n",
    "\n",
    "            if u.find(\"g\") == 0:\n",
    "                measure[i][0] = n*1000\n",
    "                # measure[i][1]=str(measure[i][1]).replace(\"g\",\"mg\")\n",
    "\n",
    "        solved_col = pd.Series(measure)\n",
    "\n",
    "        return solved_col\n",
    "    \n",
    "    # Method that calculates the standard deviation with a number list and the mean, but use np.std() instead\n",
    "    def stdCalculation(numList, mean):\n",
    "        n = len(numList)+1\n",
    "        soma = 0\n",
    "        for x in numList:\n",
    "            soma += (x-mean)**2\n",
    "        std = math.sqrt((soma)/n)\n",
    "        return std\n",
    "\n",
    "    # Method to calculate the z score for each number in a array of numbers, returns a list of z-scores of each number relevant to the array\n",
    "    def z_scorer(nums: list, mean: float or int, std: float or int):\n",
    "\n",
    "        z_scores = []\n",
    "        for x in nums:\n",
    "            z = (x-mean)/std\n",
    "            z_scores.append(z)\n",
    "        return z_scores\n",
    "\n",
    "    # Most of the action happens here\n",
    "    def idOutliers(df: pd.DataFrame, name_col: str = \"Drug\", value_col: str = \"Dose\", max_z: float = 1.8, convert_to_p: bool=True):\n",
    "        dict_rows = {}\n",
    "        means = {}\n",
    "        # Comment if you have empty values\n",
    "        df = df.dropna(axis=0, how=\"all\")\n",
    "        \n",
    "        if convert_measure:\n",
    "            values = [num for num, mg in df.loc[:, value_col]]\n",
    "        else:\n",
    "            values = [num for num in df.loc[:, value_col]]\n",
    "        \n",
    "        names = [drugs for drugs in df.loc[:, name_col] if type(drugs) is str]\n",
    "        for i, name in enumerate(names):\n",
    "            if name==\"\" or name==\"-\":\n",
    "                name=\"Empty\"\n",
    "                \n",
    "            if name not in dict_rows:\n",
    "                dict_rows[name] = []\n",
    "                \n",
    "                dict_rows[name].append(values[i])\n",
    "            else:\n",
    "                dict_rows[name].append(values[i])\n",
    "\n",
    "        for n in dict_rows:\n",
    "            media = []\n",
    "            if len(dict_rows[n]) > 1 and type(dict_rows[n]) is float:\n",
    "                means[n] = np.mean(dict_rows[n])\n",
    "\n",
    "                if dict_rows[n][0]!=0 and means[n]/dict_rows[n][0] != 1:\n",
    "                    std = np.std(dict_rows[n])\n",
    "                else:\n",
    "                    std = 1\n",
    "\n",
    "                z = z_scorer(dict_rows[n], means[n], std)\n",
    "\n",
    "                for _i, i in enumerate(z):\n",
    "                    if abs(i) <= max_z:\n",
    "                        media.append(dict_rows[n][_i])\n",
    "\n",
    "                med = np.mean(media)\n",
    "                # atrubutes where in the column specified is equal to the name of the current row, and replaces the value (dose) of that row\n",
    "                if convert_to_p:\n",
    "                    df.loc[df[name_col] == n, value_col] = -math.log10(med)\n",
    "                else:\n",
    "                    df.loc[df[name_col] == n, value_col] = med\n",
    "            else:\n",
    "                if convert_to_p:\n",
    "                    if dict_rows[n][0] <= 0:\n",
    "                        df.loc[df[name_col] == n, value_col] = dict_rows[n][0]\n",
    "                    else: \n",
    "                        df.loc[df[name_col] == n, value_col] = -math.log10(dict_rows[n][0])\n",
    "                else:\n",
    "                    df.loc[df[name_col] == n, value_col] = dict_rows[n][0]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    # computes in the order necessary to generate the dataframes\n",
    "    def organize(df,name):\n",
    "        # read\n",
    "        print(name)    \n",
    "        # convert?\n",
    "        if convert_measure:\n",
    "            new_doses = convertTo_mg(df, values_col)\n",
    "            df[values_col] = new_doses\n",
    "        # generate\n",
    "        df = standardize_with_and_out_stereo(df)\n",
    "        z = idOutliers(df, duplicate_identifier_column, values_col, max_z_score, convert_to_p)\n",
    "        z = z.drop_duplicates(keep=\"first\",subset=duplicate_identifier_column)\n",
    "        z.to_csv(f\"./data/{name}.csv\")\n",
    "        print(f\"Generated: {name}\")\n",
    "\n",
    "    # Made to work with a single file and a list of files\n",
    "    def read_through_files(files):\n",
    "\n",
    "        if type(files) is str:\n",
    "            name=result_name\n",
    "            name=name.replace(\".xlsx\",\"\")\n",
    "            name=name.replace(\".csv\",\"\")\n",
    "            if files.find(\".csv\")!=-1:\n",
    "                df=pd.read_csv(files,delimiter=\",\")\n",
    "                organize(df,name)\n",
    "            else:\n",
    "                sheets = pd.ExcelFile(files).sheet_names\n",
    "                if len(sheets)>1:\n",
    "                    for sheet in sheets:\n",
    "                        if sheet != \".\":\n",
    "                            name=sheet\n",
    "                            df=pd.read_excel(files,sheet_name=sheet)\n",
    "                            organize(df,name)\n",
    "                else:\n",
    "                    for sheet in sheets:\n",
    "                        if sheet != \".\":\n",
    "                            #name=sheet\n",
    "                            df=pd.read_excel(files,sheet_name=sheet)\n",
    "                            organize(df,name)\n",
    "        else:\n",
    "            for file in files:\n",
    "                name=str(file).replace(path_to_files,\"\")\n",
    "                name=name.replace(\".xlsx\",\"\")\n",
    "                name=name.replace(\".csv\",\"\")\n",
    "                if file.find(\".csv\")!=-1:\n",
    "                    df=pd.read_csv(file,delimiter=\",\")\n",
    "                    organize(df,name)\n",
    "                else:   \n",
    "                    sheets = pd.ExcelFile(file).sheet_names\n",
    "                    if len(sheets)>1:\n",
    "                        for sheet in sheets:\n",
    "                            if sheet != \".\":\n",
    "                                name=sheet\n",
    "                                df=pd.read_excel(file,sheet_name=sheet)\n",
    "                                organize(df,name)\n",
    "                    else:\n",
    "                        for sheet in sheets:\n",
    "                            if sheet != \".\":\n",
    "                                #name=sheet\n",
    "                                df=pd.read_excel(file,sheet_name=sheet)\n",
    "                                organize(df,name)\n",
    "\n",
    "    read_through_files(files=files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run to execute\n",
    "###### Equivalent to if __name__ == __main__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Hepatic necrosis\n",
      "Generated: \\Hepatic necrosis\n",
      "\\Hepatic Steatosis\n",
      "Generated: \\Hepatic Steatosis\n",
      "\\Hepatitis\n",
      "Generated: \\Hepatitis\n",
      "\\Hepatomegaly\n",
      "Generated: \\Hepatomegaly\n",
      "\\Liver disorder\n",
      "Generated: \\Liver disorder\n",
      "\\Liver injury\n",
      "Generated: \\Liver injury\n"
     ]
    }
   ],
   "source": [
    "# Execute everything\n",
    "main(s_file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
